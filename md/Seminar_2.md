
---


## Задания Семинара 2

1. **Sanity-checks:**

   * зафиксировать случайные сиды для Python/NumPy/PyTorch;
   * проверить загрузку датасета и аугментации;
   * выполнить эксперимент «overfit на нескольких батчах» (добиться снижения train-loss и роста accuracy до \~100%).

2. **Логирование:**

   * поднять TensorBoard `SummaryWriter`;
   * писать в логи динамику лосса, accuracy, learning rate;
   * добавить гистограммы весов и градиентов, примеры изображений;
   * проверить, что кривые ведут себя правдоподобно.

3. **Профилировка:**

   * использовать `torch.profiler` и плагин TensorBoard;
   * собрать trace на 50–100 итерациях;
   * интерпретировать таймлайн: выявить «горячие» операции и проблемы с `DataLoader`.

4. **Базовая CNN:**

   * обучить небольшую CNN на своём мини-датасете;
   * сохранить чекпойнт, логи TensorBoard и trace профайлера;
   * убедиться в устойчивой сходимости.

5. **ViT-Tiny (linear probe):**

   * загрузить предобученный ViT-Tiny (через `timm` или `torchvision`);
   * заморозить бэкон, обучить линейную «голову»;
   * сравнить кривые обучения и метрики с CNN;
   * зафиксировать таблицу метрик (accuracy, macro-F1), confusion matrix, логи TensorBoard.

---

